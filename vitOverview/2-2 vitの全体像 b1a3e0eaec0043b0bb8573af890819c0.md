# 2-2 vitの全体像

![スクリーンショット 2022-11-21 21.22.09.png](2-2%20vit%E3%81%AE%E5%85%A8%E4%BD%93%E5%83%8F%20b1a3e0eaec0043b0bb8573af890819c0/%25E3%2582%25B9%25E3%2582%25AF%25E3%2583%25AA%25E3%2583%25BC%25E3%2583%25B3%25E3%2582%25B7%25E3%2583%25A7%25E3%2583%2583%25E3%2583%2588_2022-11-21_21.22.09.png)

# ① Input Layer

![スクリーンショット 2022-11-21 21.24.21.png](2-2%20vit%E3%81%AE%E5%85%A8%E4%BD%93%E5%83%8F%20b1a3e0eaec0043b0bb8573af890819c0/%25E3%2582%25B9%25E3%2582%25AF%25E3%2583%25AA%25E3%2583%25BC%25E3%2583%25B3%25E3%2582%25B7%25E3%2583%25A7%25E3%2583%2583%25E3%2583%2588_2022-11-21_21.24.21.png)

## step1: 入力画像をPatchに分割

## step2: Liner Projectio of Flattened Patches

## step3: クラストークン、PatchのベクトルをTransfomer Encoderへ入力

# ② Trarnsformer Encoder

![Untitled](2-2%20vit%E3%81%AE%E5%85%A8%E4%BD%93%E5%83%8F%20b1a3e0eaec0043b0bb8573af890819c0/Untitled.png)

## step1: Multi-Head Self-Attention

## step2: MLP(多層パーセプロトロン)

## step3: クラストークンを出力

# ③出力層

![スクリーンショット 2022-11-21 21.49.36.png](2-2%20vit%E3%81%AE%E5%85%A8%E4%BD%93%E5%83%8F%20b1a3e0eaec0043b0bb8573af890819c0/%25E3%2582%25B9%25E3%2582%25AF%25E3%2583%25AA%25E3%2583%25BC%25E3%2583%25B3%25E3%2582%25B7%25E3%2583%25A7%25E3%2583%2583%25E3%2583%2588_2022-11-21_21.49.36.png)

## step1: MLP(多層パーセプトロン) Head